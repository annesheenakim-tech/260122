import io
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

st.set_page_config(page_title="ê¸°ì˜¨ ë¹„êµ(ê°™ì€ ë‚ ì§œ ëŒ€ë¹„)", layout="wide")

DEFAULT_CSV_PATH = "ta_20260122174530.csv"

REQUIRED_COLUMNS = ["ë‚ ì§œ", "ì§€ì ", "í‰ê· ê¸°ì˜¨(â„ƒ)", "ìµœì €ê¸°ì˜¨(â„ƒ)", "ìµœê³ ê¸°ì˜¨(â„ƒ)"]
TEMP_COLS = ["í‰ê· ê¸°ì˜¨(â„ƒ)", "ìµœì €ê¸°ì˜¨(â„ƒ)", "ìµœê³ ê¸°ì˜¨(â„ƒ)"]

# -----------------------------
# Utilities
# -----------------------------
def read_csv_robust(file_like) -> pd.DataFrame:
    """
    KMA ê³„ì—´ CSVëŠ” ì¢…ì¢… cp949/euc-kr/utf-8-sig ë“±ì´ ì„ì—¬ ìˆì–´ì„œ
    ëª‡ ê°€ì§€ ì¸ì½”ë”©ì„ ìˆœì°¨ ì‹œë„.
    """
    encodings_to_try = ["utf-8-sig", "utf-8", "cp949", "euc-kr"]
    last_err = None
    for enc in encodings_to_try:
        try:
            if isinstance(file_like, (str, bytes)):
                df = pd.read_csv(file_like, encoding=enc)
            else:
                # Uploaded file: streamlit UploadedFile (BytesIO)
                raw = file_like.read()
                df = pd.read_csv(io.BytesIO(raw), encoding=enc)
            return df
        except Exception as e:
            last_err = e
            # ì—…ë¡œë“œ íŒŒì¼ì€ read()ë¥¼ ì†Œëª¨í•˜ë¯€ë¡œ, ì‹¤íŒ¨ ì‹œ ë‹¤ì‹œ ì„¸íŒ… í•„ìš”:
            if hasattr(file_like, "seek"):
                file_like.seek(0)
            continue
    raise last_err

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # ì»¬ëŸ¼ëª… ì¢Œìš° ê³µë°±/íƒ­ ì œê±°
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    # ë‚ ì§œ ì»¬ëŸ¼ì´ íƒ­/ê³µë°±ì„ í¬í•¨í•˜ëŠ” ê²½ìš°ê°€ ìˆì–´ ê°’ë„ strip
    if "ë‚ ì§œ" in df.columns:
        df["ë‚ ì§œ"] = df["ë‚ ì§œ"].astype(str).str.strip()

    # í•„ìš”í•œ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
    missing = [c for c in REQUIRED_COLUMNS if c not in df.columns]
    if missing:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}\ní˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")

    # íƒ€ì… ë³€í™˜
    df["ì§€ì "] = pd.to_numeric(df["ì§€ì "], errors="coerce").astype("Int64")

    # ë‚ ì§œ íŒŒì‹±
    df["ë‚ ì§œ_dt"] = pd.to_datetime(df["ë‚ ì§œ"], errors="coerce")
    # ê¸°ì˜¨ íŒŒì‹±
    for c in TEMP_COLS:
        df[c] = pd.to_numeric(df[c], errors="coerce")

    # month-day í‚¤
    df["ì›”ì¼"] = df["ë‚ ì§œ_dt"].dt.strftime("%m-%d")
    df["ì—°ë„"] = df["ë‚ ì§œ_dt"].dt.year

    # ì™„ì „ í•„ìˆ˜(ë‚ ì§œ, ì§€ì ) ì—†ëŠ” í–‰ ì œê±°
    df = df.dropna(subset=["ë‚ ì§œ_dt", "ì§€ì "])
    df["ì§€ì "] = df["ì§€ì "].astype(int)

    return df

def merge_datasets(base: pd.DataFrame, extra: pd.DataFrame) -> pd.DataFrame:
    # ì¤‘ë³µ ì œê±° ê¸°ì¤€: (ë‚ ì§œ_dt, ì§€ì ) ë™ì¼í•˜ë©´ extraê°€ ìš°ì„ í•˜ë„ë¡ ë’¤ì— concat í›„ drop_duplicates keep='last'
    merged = pd.concat([base, extra], ignore_index=True)
    merged = merged.sort_values(["ë‚ ì§œ_dt", "ì§€ì "])
    merged = merged.drop_duplicates(subset=["ë‚ ì§œ_dt", "ì§€ì "], keep="last")
    return merged

def compute_day_stats(df_station: pd.DataFrame, target_date: pd.Timestamp) -> dict:
    """
    ê°™ì€ ì›”ì¼(ì˜ˆ: 01-22)ì˜ ê³¼ê±° ë¶„í¬ ëŒ€ë¹„ ì„ íƒ ë‚ ì§œê°€ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ì§€ ê³„ì‚°.
    """
    if pd.isna(target_date):
        return {}

    md = target_date.strftime("%m-%d")
    day_pool = df_station[df_station["ì›”ì¼"] == md].copy()

    # target row(í•´ë‹¹ ë‚ ì§œ ì •í™•íˆ)
    target_row = df_station[df_station["ë‚ ì§œ_dt"] == target_date].copy()

    out = {"month_day": md, "pool_n": int(day_pool.shape[0])}

    for col in TEMP_COLS:
        pool_vals = day_pool[col].dropna().values
        if pool_vals.size == 0:
            out[col] = None
            continue

        # ì„ íƒ ë‚ ì§œ ê°’
        tval = target_row[col].dropna().values
        tval = float(tval[0]) if tval.size > 0 else np.nan

        mean = float(np.mean(pool_vals))
        std = float(np.std(pool_vals, ddof=1)) if pool_vals.size >= 2 else np.nan
        median = float(np.median(pool_vals))

        # í¼ì„¼íƒ€ì¼(ì„ íƒê°’ì´ ë¶„í¬ì—ì„œ ì–´ëŠ ìœ„ì¹˜ì¸ì§€)
        if np.isfinite(tval):
            pct = float((pool_vals <= tval).mean() * 100.0)
            # ë­í¬(ë¥->1, ì¶¥->1 ë‘˜ ë‹¤ ë³´ê³  ì‹¶ìœ¼ë©´ 2ê°œ)
            rank_hot = int(np.sum(pool_vals > tval) + 1)   # í° ê°’ì¼ìˆ˜ë¡ ë” ë¥ë‹¤ê³  ê°€ì •
            rank_cold = int(np.sum(pool_vals < tval) + 1)  # ì‘ì€ ê°’ì¼ìˆ˜ë¡ ë” ì¶¥ë‹¤ê³  ê°€ì •
            delta = float(tval - mean)
            z = float(delta / std) if (np.isfinite(std) and std > 0) else np.nan
        else:
            pct, rank_hot, rank_cold, delta, z = np.nan, None, None, np.nan, np.nan

        out[col] = {
            "target": tval,
            "mean": mean,
            "median": median,
            "std": std,
            "delta": delta,
            "z": z,
            "percentile": pct,
            "rank_hot": rank_hot,
            "rank_cold": rank_cold,
            "pool_min": float(np.min(pool_vals)),
            "pool_max": float(np.max(pool_vals)),
            "pool_count": int(pool_vals.size),
        }

    return out

def make_distribution_plot(df_station: pd.DataFrame, target_date: pd.Timestamp, temp_col: str):
    md = target_date.strftime("%m-%d")
    pool = df_station[df_station["ì›”ì¼"] == md].copy()
    pool = pool.dropna(subset=[temp_col])

    fig = go.Figure()

    # ë°”ì´ì˜¬ë¦°(ë¶„í¬)
    fig.add_trace(go.Violin(
        y=pool[temp_col],
        name=f"{md} ë¶„í¬",
        box_visible=True,
        meanline_visible=True,
        points="all",
        jitter=0.3,
        scalemode="width"
    ))

    # ì„ íƒê°’ ë§ˆì»¤
    target_row = df_station[df_station["ë‚ ì§œ_dt"] == target_date].dropna(subset=[temp_col])
    if not target_row.empty:
        tval = float(target_row.iloc[0][temp_col])
        fig.add_trace(go.Scatter(
            x=[f"{md} ë¶„í¬"],
            y=[tval],
            mode="markers",
            name="ì„ íƒ ë‚ ì§œ",
            marker=dict(size=14, symbol="diamond")
        ))

    fig.update_layout(
        title=f"{temp_col} â€” ê°™ì€ ì›”ì¼({md}) ê³¼ê±° ë¶„í¬ vs ì„ íƒ ë‚ ì§œ",
        yaxis_title=temp_col,
        xaxis_title="",
        height=450
    )
    return fig

def make_window_timeseries_plot(df_station: pd.DataFrame, target_date: pd.Timestamp, temp_col: str, window_days: int = 30):
    start = target_date - pd.Timedelta(days=window_days)
    end = target_date + pd.Timedelta(days=window_days)

    win = df_station[(df_station["ë‚ ì§œ_dt"] >= start) & (df_station["ë‚ ì§œ_dt"] <= end)].copy()
    win = win.sort_values("ë‚ ì§œ_dt")

    # ê°™ì€ ì›”ì¼ ê¸°ì¤€ ê³¼ê±° í‰ê· (ì „í›„ ì°½ ì „ì²´ì— ëŒ€í•´ í•´ë‹¹ ì›”ì¼ í‰ê· ì„ ë§¤í•‘)
    md_mean_map = (
        df_station.dropna(subset=[temp_col])
        .groupby("ì›”ì¼")[temp_col].mean()
        .to_dict()
    )
    win["clim_mean_same_md"] = win["ì›”ì¼"].map(md_mean_map)

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=win["ë‚ ì§œ_dt"], y=win[temp_col],
        mode="lines+markers",
        name="ê´€ì¸¡ì¹˜"
    ))

    fig.add_trace(go.Scatter(
        x=win["ë‚ ì§œ_dt"], y=win["clim_mean_same_md"],
        mode="lines",
        name="ê°™ì€ ì›”ì¼ ì¥ê¸°í‰ê· "
    ))

    # ì„ íƒì¼ vertical line
    fig.add_vline(x=target_date, line_width=2, line_dash="dash")

    fig.update_layout(
        title=f"{temp_col} â€” ì„ íƒì¼ ì „í›„ {window_days}ì¼(ì§€ì ë³„)",
        xaxis_title="ë‚ ì§œ",
        yaxis_title=temp_col,
        height=450
    )
    return fig

# -----------------------------
# Load & App UI
# -----------------------------
st.title("ğŸŒ¡ï¸ ê¸°ì˜¨ ë¹„êµ ëŒ€ì‹œë³´ë“œ â€” ê°™ì€ ë‚ ì§œ(ì›”-ì¼) ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ì¶¥/ë¥?")
st.caption("ê¸°ë³¸ ë°ì´í„°ëŠ” ìë™ íƒ‘ì¬ë˜ê³ , ê°™ì€ í˜•ì‹ì˜ CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ í•©ì³ì„œ ë¶„ì„í•©ë‹ˆë‹¤. (Plotly ì¸í„°ë™í‹°ë¸Œ ê·¸ë˜í”„)")

with st.sidebar:
    st.header("ë°ì´í„°")
    uploaded = st.file_uploader("ì¶”ê°€ CSV ì—…ë¡œë“œ(ê°™ì€ í˜•ì‹)", type=["csv"])

@st.cache_data(show_spinner=False)
def load_base() -> pd.DataFrame:
    df0 = read_csv_robust(DEFAULT_CSV_PATH)
    df0 = normalize_columns(df0)
    return df0

base_df = load_base()

if uploaded is not None:
    extra_df = read_csv_robust(uploaded)
    extra_df = normalize_columns(extra_df)
    df = merge_datasets(base_df, extra_df)
    st.sidebar.success(f"ì¶”ê°€ ë°ì´í„° ë³‘í•© ì™„ë£Œ: +{extra_df.shape[0]:,}í–‰ (ì´ {df.shape[0]:,}í–‰)")
else:
    df = base_df

# ê²°ì¸¡ì¹˜ ìš”ì•½(ê°„ë‹¨)
with st.expander("ğŸ” ê²°ì¸¡ì¹˜ ìš”ì•½ ë³´ê¸°", expanded=False):
    miss = df[REQUIRED_COLUMNS].isna().sum().rename("ê²°ì¸¡ì¹˜ ê°œìˆ˜").to_frame()
    st.dataframe(miss, use_container_width=True)

# ì§€ì  ì„ íƒ
stations = sorted(df["ì§€ì "].dropna().unique().tolist())
default_station = stations[0] if stations else None

colA, colB, colC = st.columns([1, 1, 2], vertical_alignment="top")

with colA:
    station = st.selectbox("ì§€ì  ì„ íƒ", options=stations, index=0)

df_station = df[df["ì§€ì "] == station].copy()
df_station = df_station.sort_values("ë‚ ì§œ_dt")

# ê¸°ë³¸ ë‚ ì§œ: ìµœì‹  ë‚ ì§œ
latest_date = df_station["ë‚ ì§œ_dt"].max()

with colB:
    # Streamlit date_inputì€ dateë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ Timestampë¡œ ë³€í™˜
    chosen_date = st.date_input(
        "ë¹„êµí•  ë‚ ì§œ(ê¸°ë³¸=ìµœì‹ )",
        value=(latest_date.date() if pd.notna(latest_date) else None)
    )
    target_date = pd.to_datetime(chosen_date)

# target_dateê°€ ë°ì´í„°ì— ì—†ìœ¼ë©´ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œë¡œ ìŠ¤ëƒ…
if target_date not in set(df_station["ë‚ ì§œ_dt"]):
    # ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ
    diffs = (df_station["ë‚ ì§œ_dt"] - target_date).abs()
    nearest = df_station.loc[diffs.idxmin(), "ë‚ ì§œ_dt"]
    st.info(f"ì„ íƒí•œ ë‚ ì§œ({target_date.date()})ê°€ ë°ì´í„°ì— ì—†ì–´ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ({nearest.date()})ë¡œ ë¹„êµí•©ë‹ˆë‹¤.")
    target_date = nearest

stats = compute_day_stats(df_station, target_date)

# -----------------------------
# KPI Cards
# -----------------------------
with colC:
    st.subheader("ìš”ì•½(ê°™ì€ ì›”-ì¼ ê³¼ê±° ëŒ€ë¹„)")
    md = stats.get("month_day", "")
    pool_n = stats.get("pool_n", 0)
    st.write(f"- ë¹„êµ ê¸°ì¤€: **ì›”-ì¼ {md}** (í•´ë‹¹ ì§€ì ì—ì„œ ê´€ì¸¡ì¹˜ **{pool_n:,}ê°œ**)")
    target_row = df_station[df_station["ë‚ ì§œ_dt"] == target_date][["ë‚ ì§œ_dt"] + TEMP_COLS].head(1)
    if not target_row.empty:
        st.dataframe(target_row.rename(columns={"ë‚ ì§œ_dt": "ë‚ ì§œ"}), use_container_width=True)

def metric_block(colname: str, label: str):
    d = stats.get(colname)
    if not isinstance(d, dict) or not np.isfinite(d.get("target", np.nan)):
        st.warning(f"{label}: ì„ íƒ ë‚ ì§œ ê°’ì´ ì—†ê±°ë‚˜ ë¹„êµ ë¶ˆê°€")
        return

    t = d["target"]
    delta = d["delta"]
    pct = d["percentile"]
    z = d["z"]

    # í•´ì„ ë¬¸ì¥(ê°„ë‹¨)
    # pct ë‚®ìœ¼ë©´ ì¶¥ê³ , ë†’ìœ¼ë©´ ë¥ë‹¤ê³  í•´ì„
    if np.isfinite(pct):
        if pct <= 10:
            interp = "ì—­ëŒ€ì ìœ¼ë¡œ ê½¤ ì¶”ìš´ í¸(í•˜ìœ„ 10%)"
        elif pct >= 90:
            interp = "ì—­ëŒ€ì ìœ¼ë¡œ ê½¤ ë”ìš´ í¸(ìƒìœ„ 10%)"
        else:
            interp = "ëŒ€ì²´ë¡œ í‰ë…„ ë²”ìœ„"
    else:
        interp = "ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚° ë¶ˆê°€"

    c1, c2, c3, c4 = st.columns(4)
    c1.metric(f"{label} (ì„ íƒì¼)", f"{t:.1f}â„ƒ")
    c2.metric("ê°™ì€ ì›”-ì¼ í‰ê· ", f"{d['mean']:.1f}â„ƒ", f"{delta:+.1f}â„ƒ")
    c3.metric("í¼ì„¼íƒ€ì¼", f"{pct:.1f}%" if np.isfinite(pct) else "NA")
    c4.metric("z-score", f"{z:.2f}" if np.isfinite(z) else "NA")
    st.caption(f"í•´ì„: {interp}")

st.divider()
st.subheader("â‘  í‰ê· /ìµœì €/ìµœê³  ê°ê° ë¹„êµ")

tabs = st.tabs(["í‰ê· ê¸°ì˜¨", "ìµœì €ê¸°ì˜¨", "ìµœê³ ê¸°ì˜¨"])
tab_cols = [("í‰ê· ê¸°ì˜¨(â„ƒ)", "í‰ê· ê¸°ì˜¨"), ("ìµœì €ê¸°ì˜¨(â„ƒ)", "ìµœì €ê¸°ì˜¨"), ("ìµœê³ ê¸°ì˜¨(â„ƒ)", "ìµœê³ ê¸°ì˜¨")]

for tab, (cname, label) in zip(tabs, tab_cols):
    with tab:
        metric_block(cname, label)

        left, right = st.columns(2)
        with left:
            fig1 = make_distribution_plot(df_station, target_date, cname)
            st.plotly_chart(fig1, use_container_width=True)

        with right:
            fig2 = make_window_timeseries_plot(df_station, target_date, cname, window_days=30)
            st.plotly_chart(fig2, use_container_width=True)

st.divider()

# -----------------------------
# Download merged dataset (optional)
# -----------------------------
with st.expander("ğŸ“¦ ë³‘í•©ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", expanded=False):
    out_csv = df.drop(columns=["ë‚ ì§œ_dt"], errors="ignore").to_csv(index=False).encode("utf-8-sig")
    st.download_button("ë³‘í•© ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ(utf-8-sig)", data=out_csv, file_name="merged_temperature.csv", mime="text/csv")
